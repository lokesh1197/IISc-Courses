* QR Factorization
** Classical Gram-Schmidt Orthogonalization (best for parallelization)
Numerically unstable Good for parallelization

Operation count:
\[\begin{aligned}
for j = 1 to n
  v_j = a_j
  for i = 1 to j-1
    r_{ij} = q_i^Ta_j     \rightarrow m multiplications + (m-1) additions
    v_j = v_j - r_{ij}q_i \rightarrow m multiplications + m subtractions
  r_{jj} = ||v_j||_2
  q_i = v_j

  Total work \sim 4m flops
  Total flops = \sum_{j=1}^n\sum_{i=1}^{j-1}4m = (\frac{n(n+1)}{2} - 1)4m
              = O(2mn^2)
\end{aligned}\]

** Modified Gram-Schmidt Orthogonalization
Numerically stable and accuracy of orthogonality is dependent on K(A)

** Householder Factorization
Triangularization Numerically stable and accuracy of orthogonality is
better than modified GS.

Let \(Q_n...Q_3Q_2Q_1A = R\). The product \(Q = Q_1^TQ_2^T...Q_n^T\) is
orthogonal, \(A=QR\) is the full QR factorizaiton of A

#+begin_export latex
A = \begin{pmatrix}
       ,* & * & ... & *\\
       ,* & * & ... & *\\
       \vdots & \vdots* & \ddots & \vdots \\
       ,* & * & ... & *\\
     \end{pmatrix}
     \rightarrow^{Q_1}
     \begin{pmatrix}
       ,* & * & ... & *\\
       0 & * & ... & *\\
       \vdots & \vdots* & \ddots & \vdots \\
       0 & * & ... & *\\
     \end{pmatrix}
     \rightarrow^{Q_2}
     \begin{pmatrix}
       ,* & * & ... & *\\
       0 & * & ... & *\\
       \vdots & \vdots* & \ddots & \vdots \\
       0 & 0 & ... & *\\
     \end{pmatrix}
     ... 
#+end_export
$ A = \begin{pmatrix}
        * & * & ... & *\\
        * & * & ... & *\\
        \vdots & \vdots* & \ddots & \vdots \\
        * & * & ... & *\\
      \end{pmatrix}
      \rightarrow^{Q_1}
      \begin{pmatrix}
        * & * & ... & *\\
        0 & * & ... & *\\
        \vdots & \vdots* & \ddots & \vdots \\
        0 & * & ... & *\\
      \end{pmatrix}
      \rightarrow^{Q_2}
      \begin{pmatrix}
        * & * & ... & *\\
        0 & * & ... & *\\
        \vdots & \vdots* & \ddots & \vdots \\
        0 & 0 & ... & *\\
      \end{pmatrix}
      ... $

\(Q_k = \begin{pmatrix} I_{(k-1, k-1)} & 0 \\ 0 & F_{(m-k+1, m-k+1)} \end{pmatrix}\)

\(x \rightarrow^F Fx = ||x||e_1\)

Householder reflector: F \(F = (I - 2uu^T)\)

\[\begin{aligned}
  for k = 1:n
    x = A(k:m, k)
    v_k = sgn(x_1)||x||e_1 + x
    v_k=\frac{v_k}{||v_k||_2}
    A(k:m, k:n) = A(k:m, k:n) - 2v_kv_k^TA(k:m, k:n)\end{aligned}\]

Algorithm for \(Q^Tb\) \[\begin{aligned}
  for k = 1:n
    b(k:m) = b(k:m) - 2v_kv_k^Tb(k:m)\end{aligned}\]

flops: \(2mn^2 - \frac{2}{3}n^3\)

** Check for Orthogonality
\[\begin{aligned}
  CGS:         &||I - Q^TQ|| = O(K(A)^{2}\epsilon_{machine})\\
  MGS:         &||I - Q^TQ|| = O(K(A)\epsilon_{machine})\\
  Householder: &||I - Q^TQ|| = O(\epsilon_{machine})\\\end{aligned}\]

** Stability of Householder triangularization
$\tilde{\mathbf{Q}}\tilde{R} = \mathbf{A} + \delta \mathbf{A}$, $\frac{||\delta\mathbf{A}||}{||\mathbf{A}||} = O(\epsilon_{machine})$
$\tilde{\mathbf{Q}} = \mathbf{Q_1}\mathbf{Q_2}...\mathbf{Q_k}$

Householder triangularization is backwards stable.
$\frac{||\tilde{\mathbf{Q}} - \mathbf{Q}||}{||\mathbf{Q}||} = O(k\epsilon_{machine}) \implies \frac{||\tilde{\mathbf{R}} - \mathbf{R}||}{||\mathbf{R}||} = O(k\epsilon_{machine})$

** Ax = b by QR factorization
1. $\tilde{\mathbf{Q}}\tilde{\mathbf{R}} = \mathbf{A}$, $\tilde{Q}$ is product of the reflectors
2. $\tilde{\mathbf{y}} = \tilde{\mathbf{Q}}^T\mathbf{b}$, construct $Q^Tb$ without explicitly building Q
3. $\mathbf{R}\tilde{\mathbf{x}} = \mathbf{\tilde{y}}$, solving by backward stability
   
$\tilde{\mathbf{x}}$ is a solution of $(\mathbf{A} + \delta \mathbf{A})\tilde{\mathbf{x}} = \mathbf{b}$, for some $\frac{||\delta \mathbf{A}||}{||\mathbf{A}||} = O(\epsilon_{machine})$
* Least Squares
$\mathbf{Ax} = \mathbf{b}$, when the number of equations is more than the number of variables

Idea of least squares is to find ~x~ that minimizes 2-norm of the residual ~r = b - Ax~
Which leads to $x = A(A^TA)^{-1}b$
